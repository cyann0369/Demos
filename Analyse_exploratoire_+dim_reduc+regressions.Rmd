---
title: "Projet 2"
output: html_document
date: "2024-11-04"
---

#1. Chargement des librairies

```{r}
devtools::install_github("r-lib/conflicted", force = TRUE)
library(conflicted)
library(readxl)
library(tidyverse)
library(dplyr)
library(outliers)
library(lattice)
library(reactable)
library(psych)
library(ggplot2)
library(gridExtra)
library(reshape2)
library(ggrain)
library(corrr)
library(ggcorrplot)
library(corrplot)
library(compositions)
library(FactoMineR)
library(factoextra)
library(broom)
library(pls)
library(splines)
library(randomForest)
library(e1071)
library(caret)
library(stats)
```

Certains packages utilisés pour ce projet contiennent des fonctions qui ont le même nom, ce qui cause des conflits lors du chargement. Pour y remédier, nous installons le package "conflicted" qui permet de faire un choix des fonctions à utiliser.


#2. Chargement des données

```{r}
df <- read_excel("C:\\Users\\sasse\\Downloads\\MSc IA\\Projet 2\\data_abs.xlsx")
attach(df)

```
Nous utilisons la fonction attach pour rendre accessible les objets du dataframe sans avoir à utiliser à chaque fois le nom du dataframe. Exemple: mean(df$txabs) permet d'afficher le taux d'abstention moyen; en utilisant préalablement attach, on peut directement écrire mean(txabs).

R a attribué le nom "...1" à la colonne contenant les numéros d'ordre des départements, car cette colonne était sans nom dans le fichier original. Nous supprimerons cette colonne dans la suite, car elle n'apporte aucune information, les départements ayant déjà des codes.

#3. Structure des données

Nous présentons ici une vue globale des données, comprenant:

- la dimension du dataframe (96 lignes, 14 colonnes)

- le type de données dans chaque colonne.

```{r}

dim(df)

df$...1 <- NULL  #suppression de la colonne ...1 créée automatiquement pendant l'importation des données

str(df)    #ou
glimpse(df)

```
Nous définissons ici la colonne Department comme l'index du dataframe.

```{r}

df %>%
     remove_rownames() %>%
     column_to_rownames(var = 'Department')

```

#4. Recherche de données manquantes et valeurs uniques pour les départements et leurs codes

Nous vérifions la présence de données manquantes en appliquant aux colonnes du dataframe, une fonction qui calcule la somme des valeurs manquantes (NA). Ensuite, nous vérifions la présence de doublons au niveau des départements (et de leurs codes),en affichant les valeurs uniques pour ces deux colonnes.

```{r}

na_per_column <- sapply(df, function(x) sum(is.na(x)))
print(na_per_column)

set_col <- c("Department", "Code")
unique_values <- lapply(df[set_col], unique)
print(unique_values)

```

Pas de valeurs manquantes, ni de doublons dans la base de données.

#5. Analyse univariée

##5.1. Statistiques descriptives

Nous présentons quelques statistiques descriptives des colonnes du dataframe (min, max, moyenne, quartiles, etc).

```{r}

for (col_name in names(df)) {
  cat("Summary for:", col_name, "\n")
  print(summary(df[[col_name]]))
  cat("\n")
}

```
Les distributions des différentes variables au sein des départements semblent être équilibrées, car les médianes sont très proches des moyennes pour l'ensemble des variables. En particulier, les proportions médiane moyenne de professions intermédiaires (PI) sont toutes deux égales à 24,8%; pour les autres variables (sauf Cadres), l'écart entre les deux indicateurs de tendance centrale est inférieur à 1 point de pourcentage (pp). La proportion de cadres se distingue avec une moyenne supérieure à la médiane d'environs 2 pp, donnant une intuition sur la présence de données aberrantes (potentiellement des départements avec beaucoup plus de cadres que d'autres). En moyenne, le taux d'abstention (txabs) est très proche des 20%, signifiant qu'une personne sur cinq ne vote pas. Les représentations graphiques suivantes permettront de mieux appréhender ces statistiques.

##5.2 Représentations graphiques

```{r}

# Fonction pour Boxplot et Histogramme avec courbe de densité

graphiques_uni <- function(data, variable) {
  
  boxplot <- ggplot(data, aes_string(x = "1", y = variable)) +
    geom_boxplot(outlier.colour = "red", outlier.size = 2) +
    stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = "blue", fill = "blue") +
    labs(title = paste("Boxplot de la variable", variable), y = variable) +
    theme_minimal() +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  
  histogram <- ggplot(data, aes_string(x = variable)) +
    geom_histogram(aes(y = ..density..), fill = "blue", color = "black", alpha = 0.7) +
    geom_density(color = "red", size = 1) +
    labs(title = paste("Histogramme de la variable", variable), y = "Densité") +
    theme_minimal()
  
  
  grid.arrange(boxplot, histogram, ncol = 2)
}

# Fonction appliquant <<graphiques_uni>> à toutes les colonnes numériques du dataframe

graphiques_uni_all <- function(data) {
  numeric_columns <- names(data)[sapply(data, is.numeric)]
  
  for (variable in numeric_columns) {
    graphiques_uni(data, variable)
  }
}

# Example usage with a dataframe `df`
graphiques_uni_all(df)

```
Pour chaque variable, nous présentons un boxplot et un histogramme, pour mieux visualiser les distributions. L'objectif est de décrire les variables en terme d'asymétrie et d'identifier de potentielles valeurs aberrantes.

En général, les distributions des catégories socio-professionnelles sont asymétriques, avec pour certaines des valeurs aberrantes. Seul le pourcentage d'employés semble être symétriquement distribué dans l'ensemble des départements, avec cependant une valeur particulièrement faible de 20,5% en Hauts-de-Seine.

La part d'individus vivant en HLM présente une distribution asymétrique vers la gauche, avec la majorité des départements affichant une valeur entre 5% et 20%. Les départements de Seine-Saint-Denis et Val-de-Marne se distinguent avec les plus grandes proportions de personnes vivant en HLM (respectivement 32,4% et 27,4%).

Le salaire horaire net moyen est particulièrement élevé dans les départements de Paris, Hauts-de-Seine, et Yvelines, entre 20 et 23 euros, alors qu'il est compris entre 11 et 16 euros pour la majorité des départements. Les emplois au nord de la France semble être beaucoup mieux payés que dans le reste de la France. La tendance asymétrique vers la gauche est la même en ce qui concerne le taux de pauvreté, particulièrement faible en Haute-Savoie, Yvelines et Vendée, qui se distinguent avec des valeurs autour de 10%, alors que des départements comme Seine-Saint-Denis, Haute-Corse et Aude présentent des taux de pauvreté deux fois voire trois fois plus élevés (entre 20% et 30%).

La distribution du pourcentage de personnes non diplômées est assez symétrique par rapport à celles des autres variables: pour la majorité des départements, on compte entre 30% et 35% de personnes non diplômées, avec des valeurs particulièrement faibles dans les départements de Paris et Hauts-de-Seine. Le taux de chômage est compris entre 7% et 10% dans la majorité des départements, même si les Pyrénées-Orientales se distinguent avec un taux autour de 15%.

Quant au taux d'abstention, la plupart des départements présentent des valeurs autour de 20%; la distribution est asymétrique, avec une concentration de départements ayant des taux d'abstention entre 16% et 23%; des taux exceptionnellement élevés (entre 27% et 33%) sont observés dans les départements de Seine-Saint-Denis, Corse-du Sud, et Haute-Corse. La section suivante contient le traitement effectué sur ces valeurs aberrantes du taux d'abstention.

##5.2. Gestion des valeurs aberrantes pour la variable d'intérêt

```{r}

# Affichage des départements présentant des valeurs aberrantes pour txabs

outliers_txabs <- boxplot.stats(txabs)$out

outliers_txabs_rows <- which(txabs %in% outliers_txabs)

print(df[outliers_txabs_rows,c(1,14)])

```

Ces trois départements présentent des valeurs aberrantes pour le taux d'abstention. Face aux trois options suivantes: a) supprimer les observations concernées, b) imputer par la moyenne, et c) imputer par la prochaine valeur la plus proche de la médiane sur le boxplot, nous avons choisi l'option c). Nous n'avons pas choisi l'option a, car le peu d'individus (96) de la base de données serait davantage réduit, faisant perdre de l'information nécessaire à l'analyse. Quand à l'option b, elle a été rejetée car la moyenne est très sensible aux valeurs aberrantes. L'option c nous a semblé la meilleure car elle conserve l'asymétrie des données sur les taux d'abstention, même si elle affecte très probablement les résultats de l'analyse. C'est donc l'option la moins mauvaise, considérant le fait qu'on ne puisse pas isoler les observations concernées pour les étudier séparémement (vu leur nombre).

```{r}

as.data.frame(sort(df$txabs, decreasing = TRUE))

median(df$txabs)

```
Nous assignons la valeur 23,6 du taux d'abstention à ces trois départements.

```{r}

df$txabs[df$Department == "Corse-du-Sud"] <- 23.6
df$txabs[df$Department == "Haute-Corse"] <- 23.6
df$txabs[df$Department == "Seine-Saint-Denis"] <- 23.6

reactable(df)

```

Nous vérifions ensuite l'apparition de nouvelles valeurs aberrantes.

```{r}

# Test de Grubbs (vérification de la présence d'outliers)

grubbs.test(df$txabs)

```
Après avoir remplacé les valeurs aberrantes des taux d'abstention par la valeur suivante la plus proche de la médiane, le boxplot et le test de Grubbs permettent de conclure qu'il n'y a plus d'outliers pour cette variable.


#6. Analyse bivariée

Nous étudions les variables par paire pour ressortir de potentielles liaisons entre elles. Une matrice de corrélation est calculée avec l'ensemble des variables, et ensuite, nous montrons à travers des nuages de points, la relation entre chacune des variables explicatives et le taux d'abstention

##6.1. Matrice de corrélation

```{r}


# Matrice de corrélation

matrix_corr <- function(data) {
  
  numeric_data <- data[sapply(data, is.numeric)]
  corr_matrix <- cor(numeric_data, use = "pairwise.complete.obs")
  
  corr_melted <- melt(corr_matrix)
  
  ggplot(corr_melted, aes(x = Var1, y = Var2, fill = value)) +
    geom_tile(color = "white") +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1, 1), space = "Lab", 
                         name = "Correlation") +
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
    labs(title = "Matrice de correlation", 
         x = "", y = "")
}

conflicted::conflicts_prefer(stats::cor)
matrix_corr(df)


```
Le taux d'absention est positivement corrélé au taux de pauvreté, au taux de chômage, et au pourcentage de personnes non diplômés: cela suggère que les les départements les plus défavorisés en termes d'emploi, de pouvoir de marché et d'éducation sont plus susceptibles d'enregistrer de forts taux d'abstention. Il y a également une tendance des personnes vivants en HLM à l'abstention au vote, la corrélation entre ces deux variables étant positive. Pour les autres catégories socio-professionnelles, seules les parts d'artisans et d'agriculteurs semblent être liées (négativement) au taux d'abstention; la relation entre les autres catégories et le taux est soit inexistante, soit négative mais très faible. C'est également le cas du salaire moyen, ce qui peut signifier que le salaire n'entre pas en jeu dans le choix des individus d'aller voter.


##6.2. Nuage de points, droite de régression et courbe LOESS (variables explicatives vs taux d'abstention)

```{r}

graphiques_biv <- function(data, var_interet) {
  
  numeric_columns <- setdiff(names(data)[sapply(data, is.numeric)], var_interet)
  
  for (variable in numeric_columns) {
    
    plot <- ggplot(data, aes_string(x = variable, y = var_interet)) +
      geom_point(alpha = 0.6, color = "black") + 
      geom_smooth(method = "lm", color = "blue", se = FALSE) +
      geom_smooth(method = "loess", color = "red", se = FALSE) +
      labs(title = paste(variable, "X", var_interet), 
           x = variable, y = var_interet) +
      theme_minimal()
    
    print(plot)
  }
}

graphiques_biv(df, "txabs")

```
Nous avons représenté les relations entre les variables explicatives et le taux d'abstention par des nuages de points, des droites de régression linéaire en bleu et des courbes LOESS (LOcally Estimated Scatterplot Smoothing) en rouge. L'idée est de rechercher la meilleure représentation des relations étudiées (linéaire ou non), en comparant les deux courbes.

La droite de régression confirme pour chacune des variables, le sens et l'intensité de la relation trouvée après la matrice de corrélation. Cependant, les relations sont loin d'être linéaires pour la plupart des variables; en effet, la courbe LOESS se distingue clairement de la droite de régression, surtout aux extrémités des nuages de points (exemples: employe, HLM). La présence de points d'inflexions (montées et de descentes) au niveau des courbes LOESS suggère qu'un modèle linéaire pourrait ne pas expliquer de manière performante les relations entre les variables explicatives et le taux d'abstention.

#7. Traitement spécifique des données compositionnelles

```{r}

# Séparation des variables explicatives (en compositionnelles et non compositionnelles)

df_comp <- df[, c("Ouvrier", "Employe", "PI", "Cadres","Artisant", "Agri")]
class(df_comp)

df_noncomp <- df[, c("HLM", "Salairemoy", "TxPauv", "NonDiplome","txcho", "txabs")]
class(df_noncomp)

```

```{r}

# Transformation Log-Ratio Isométrique (ILR) des données compositionnelles

comp_ilr <- ilr(df_comp)
head(comp_ilr, 5)

```

```{r}

# Nouveau dataframe df2: variables explicatives non compositionnelles et variables explicatives compositionnelles transformées

df_comp_ilr <- as.data.frame.acomp(comp_ilr)

df2 <- cbind.data.frame(df_noncomp, df_comp_ilr)

head(df2, 5)

```

#8. Réduction de dimension

##8.1. Standardisation des variables

```{r}

# Standardisation des variables non compositionnelles

df_noncomp_stand <- as.data.frame(scale(df_noncomp))
df
df_stand <- cbind(df_noncomp_stand, df_comp_ilr )

```

Les variables compositionnelles ont déjà subi une standardisation via la transformation log-ratio isométrique.


##8.2. Analyse factorielle: Composantes Principales

```{r}

# Analyse factorielle

df_pca <- df_stand %>%
  select(-txabs)

pca_result <- PCA(df_pca, scale.unit = TRUE, graph = TRUE)
pca_result$var

# Loadings des variables

var_loads <- pca_result$rotation
print(var_loads)

```

##8.3. Choix des axes principaux et des variables à conserver

Nous avons fixé un seuil minimum de 10% de contribution pour chacune des variables.

```{r}
eig.val <- get_eigenvalue(pca_result)
eig.val

var <- get_pca_var(pca_result)
var$contrib
var$cos2

fviz_eig(pca_result)

```
```{r}

# Contributions des variables aux axes 1 et 2
fviz_contrib(pca_result, choice = "var", axes = 1, top = 10)
fviz_contrib(pca_result, choice = "var", axes = 2, top = 10)

```

```{r}

contrib <- pca_result$var$contrib[, 1:2]
print(contrib)

# Contribution moyenne

nb_var <- nrow(contrib)
contrib_moyenne <- 100 / nb_var

# Sélection des variables contribuant plus que la moyenne sur l'un des axes choisis
var_choisies <- apply(contrib, 1, function(x) any(x > contrib_moyenne))

# Liste des variables pertinentes
var_choisies <- names(var_choisies[var_choisies == TRUE])

# Afficher les variables pertinentes
print(var_choisies)

```
Variables choisies: V3, V2, Salairemoy, NonDiplome, TxPauv, txcho, V1.

#9. Régressions

##9.1. Régression linéaire avec les variables sélectionnées après l'analyse factorielle (sur la base des contributions)

```{r}

#set.seed(953)

trainIndex <- createDataPartition(df_stand$txabs, p = 0.7, list = FALSE)

trainData <- df_stand[trainIndex, ]
testData  <- df_stand[-trainIndex, ]

trainControl <- trainControl(method = "cv", number = 10)

```

```{r}

modele_lm <- train(txabs ~ Salairemoy + TxPauv + NonDiplome + txcho + V1 + V2 + V3, data = trainData, method = "lm", trControl = trainControl)

print(modele_lm)

summary(modele_lm)

```
Le modèle de régression linéaire avec les variables sémectionnées après l'analyse factorielle ne permet pas d'expliquer le taux d'abstention en fonction des variables explicatives. La non significativité des coefficients, ainsi que la valeur relativement élevé du RMSE montrent l'incapacité du modèle à expliquer les relations recherchées.

```{r}

#Pouvoir pédictif du modèle

predictions_lm <- predict(modele_lm, newdata = testData)

obs_vs_pred_lm <- data.frame(Observed = testData$txabs, Predicted = predictions_lm)


rmse_lm <- sqrt(mean((obs_vs_pred_lm$Observed - obs_vs_pred_lm$Predicted)^2))
cat("RMSE:", rmse_lm)

mean(testData$txabs)

```
Très faible pouvoir prédictif du modèle, le RMSE est près de 10 fois supérieur à la moyenne.

##9.2. Régression sur les composantes principales

```{r}

modele_pcr <- train(txabs ~ Salairemoy + TxPauv + NonDiplome + txcho + V1 + V2 + V3, data = trainData, method = "pcr", trControl = trainControl)

print(modele_pcr)

summary(modele_pcr)

modele_pcr$finalModel

```
```{r}

predictions_pcr <- predict(modele_pcr, newdata = testData)

obs_vs_pred_pcr <- data.frame(Observed = testData$txabs, Predicted = predictions_pcr)

rmse_pcr <- sqrt(mean((obs_vs_pred_pcr$Observed - obs_vs_pred_pcr$Predicted)^2))
cat("RMSE:", rmse_pcr)

mean(testData$txabs)

```
Légère amélioration, sans pour autant constituer un bon modèle (prédictif ou explicatif).

##9.3. Random Forest

```{r}

grid <- expand.grid(mtry = c(2:7)) 
grid

```

```{r}

rf.fit <- train( txabs ~ Salairemoy + TxPauv + NonDiplome + txcho + V1 + V2 + V3, data=trainData, method = 'rf', trControl = trainControl, tuneGrid = grid, metric = "RMSE", ntree = 1000)

rf.fit

rf.fit$finalModel

```

```{r}

predictions <- predict(rf.fit, newdata = testData)

obs_vs_pred <- data.frame(Observed = testData$txabs, Predicted = predictions)

rmse_rf <- sqrt(mean((obs_vs_pred$Observed - obs_vs_pred$Predicted)^2))
cat("RMSE:", rmse_rf)

mean(testData$txabs)

```
Pouvoir prédictif toujours limité pour expliquer le taux d’abstention (probablement dû à des relations non linéaires complexes que le modèle n'a pas totalement capturées).

##9.4. Comparaison des modèles et choix du meilleur modèle

```{r}

# Calcul de l'AIC pour chaque modèle

# AIC pour la régression linéaire
aic_lm <- AIC(modele_lm$finalModel)

# AIC pour le modèle PCR
rss_pcr <- sum((testData$txabs - predict(modele_pcr, newdata = testData))^2)
n <- nrow(testData)
k_pcr <- 2
aic_pcr <- n*log(rss_pcr/n) + 2*k_pcr

# AIC pour la forêt aléatoire
rss_rf <- sum((testData$txabs - predict(rf.fit, newdata = testData))^2)
k_rf <- 2
aic_rf <- n * log(rss_rf / n) + 2 * k_rf

```

```{r}

# Performance des modèles

results <- data.frame(
  Model = c("Linear Regression", "PCR", "Random Forest"),
  RMSE = c(rmse_lm, rmse_pcr, rmse_rf),
  AIC = c(aic_lm, aic_pcr, aic_rf)
)

print(results)

```
Le Random Forest apporte une amélioration par rapport aux modèles de régression linéaire et de régression par les composantes principales  en termes de RMSE et d'AIC. Avec un RMSE de 0.5970692 et une valeur de -24.88045 pour l'AIC, il s'agit du meilleur modèle parmi ceux testés. 
